
@inproceedings{galileo,
  author       = {Xiong{-}Hui Chen and
                  Yang Yu and
                  Zhengmao Zhu and
                  Zhihua Yu and
                  Zhenjun Chen and
                  Chenghe Wang and
                  Yinan Wu and
                  Rong{-}Jun Qin and
                  Hongqiu Wu and
                  Ruijin Ding and
                  Fangsheng Huang},
  title        = {Adversarial Counterfactual Environment Model Learning},
  booktitle    = {Advances in Neural Information Processing Systems 36},
  year         = {2023},
}

@inproceedings{ruifeng@icml24,
  author       = {Ruifeng Chen and
                  Chengxing Jia and
                  Zefang Huang and
                  Tian{-}Shuo Liu and
                  Xu{-}Hui Liu and
                  Yang Yu},
  title        = {Offline Transition Modeling via Contrastive Energy Learning},
  booktitle    = {Proceedings of the 41th International Conference on Machine Learning},
    year={2024}
}

@article{d3rlpy,
  author  = {Takuma Seno and Michita Imai},
  title   = {d3rlpy: An Offline Deep Reinforcement Learning Library},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {315},
  pages   = {1--20},
  url     = {http://jmlr.org/papers/v23/22-0017.html}
}

@Article{football-deepmind,
author={Wang, Zhe
and Veli{\v{c}}kovi{\'{c}}, Petar
and Hennes, Daniel
and Toma{\v{s}}ev, Nenad
and Prince, Laurel
and Kaisers, Michael
and Bachrach, Yoram
and Elie, Romuald
and Wenliang, Li Kevin
and Piccinini, Federico
and Spearman, William
and Graham, Ian
and Connor, Jerome
and Yang, Yi
and Recasens, Adri{\`a}
and Khan, Mina
and Beauguerlange, Nathalie
and Sprechmann, Pablo
and Moreno, Pol
and Heess, Nicolas
and Bowling, Michael
and Hassabis, Demis
and Tuyls, Karl},
title={TacticAI: an AI assistant for football tactics},
journal={Nature Communications},
year={2024},
month={Mar},
day={19},
volume={15},
number={1},
pages={1906},
issn={2041-1723},
}



@inproceedings{dqn2016van,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{awac2020ashvin,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}


@article{ppo2017schulman,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}


@article{fusion2022jonas,
  title={Magnetic control of tokamak plasmas through deep reinforcement learning},
  author={Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de Las Casas, Diego and others},
  journal={Nature},
  volume={602},
  number={7897},
  pages={414--419},
  year={2022},
  publisher={Nature Publishing Group}
}

@article{cot2022jason,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{gpt42023achiam,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{llama2023hugo,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{llm-code2024ke,
  title={If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents},
  author={Yang, Ke and Liu, Jiateng and Wu, John and Yang, Chaoqi and Fung, Yi R and Li, Sha and Huang, Zixuan and Cao, Xu and Wang, Xingyao and Wang, Yiquan and others},
  journal={arXiv preprint arXiv:2401.00812},
  year={2024}
}

@article{voyager2023guanzhi,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}


@article{tot2023shunyu,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}

@article{llm-mcts2023zirui,
  title={Large Language Models as Commonsense Knowledge for Large-Scale Task Planning},
  author={Zhao, Zirui and Lee, Wee Sun and Hsu, David},
  journal={arXiv preprint arXiv:2305.14078},
  year={2023}
}

@book{rl@2018sutton,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{cql@2020aviral,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}


@article{mopo@2020tianhe,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}

@article{football2019karol,
  author       = {Karol Kurach and
                  Anton Raichuk and
                  Piotr Stanczyk and
                  Michal Zajac and
                  Olivier Bachem and
                  Lasse Espeholt and
                  Carlos Riquelme and
                  Damien Vincent and
                  Marcin Michalski and
                  Olivier Bousquet and
                  Sylvain Gelly},
  title        = {Google Research Football: {A} Novel Reinforcement Learning Environment},
  journal      = {CoRR},
  volume       = {abs/1907.11180},
  year         = {2019},
  url          = {http://arxiv.org/abs/1907.11180},
  eprinttype    = {arXiv},
  eprint       = {1907.11180},
  timestamp    = {Fri, 23 Sep 2022 12:49:24 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-11180.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@software {redpajama@2023together, 
    author = {Together Computer}, 
    title = {RedPajama: An Open Source Recipe to Reproduce LLaMA training dataset}, 
    month = April, year = 2023, 
    url = {https://github.com/togethercomputer/RedPajama-Data} 
}

@article{td3-bc@2021fujimoto,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@article{iql@2021kostrikov,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@inproceedings{rem@2020rishabh,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}


@article{bear@aviral2019,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@article{bellman@2021tengyang,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={6683--6694},
  year={2021}
}


@article{morel@2022rahul,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21810--21823},
  year={2020}
}


@inproceedings{pcm,
  author       = {Ruifeng Chen and
                  Xiong{-}Hui Chen and
                  Yihao Sun and
                  Siyuan Xiao and
                  Minhui Li and
                  Yang Yu},
  title        = {Policy-conditioned Environment Models are More Generalizable},
  booktitle    = {41st International Conference on Machine Learning},
year ={2024}
}

@article{maple@2023xionghui,
  title={Offline Model-Based Adaptable Policy Learning for Decision-Making in Out-of-Support Regions},
  author={Chen, Xiong-Hui and Luo, Fan-Ming and Yu, Yang and Li, Qingyang and Qin, Zhiwei and Shang, Wenjie and Ye, Jieping},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@article{brac@2019yifan,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{rag@2020patick,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}


@article{inner@2022wenlong,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}


@article{react@2022shunyu,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}


@inproceedings{reflexion@2023noah,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik R and Yao, Shunyu},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}


@article{offline-llm@2022machel,
  title={Can wikipedia help offline reinforcement learning?},
  author={Reid, Machel and Yamada, Yutaro and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2201.12122},
  year={2022}
}

@article{mbpo@2019michael,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}


@inproceedings{kurach2020google,
  title={Google research football: A novel reinforcement learning environment},
  author={Kurach, Karol and Raichuk, Anton and Sta{\'n}czyk, Piotr and Zaj{\k{a}}c, Micha{\l} and Bachem, Olivier and Espeholt, Lasse and Riquelme, Carlos and Vincent, Damien and Michalski, Marcin and Bousquet, Olivier and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={4501--4510},
  year={2020}
}



@misc{anvarov2020football,
  author = {Anvarov, Sarvar},
  title = {Solution ranked 35th in Kaggle Football Competition},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Sarvar-Anvarov/Google-Research-Football}},
  commit = {The specific commit hash if relevant}
}


@software{together2023redpajama,
  author = {TogetherComputer},
  title = {RedPajama: an Open Dataset for Training Large Language Models},
  month = October,
  year = 2023,
  url = {https://github.com/togethercomputer/RedPajama-Data}
}


@inproceedings{genoffline@luo2024,
  title={Reward-consistent dynamics models are strongly generalizable for offline reinforcement learning},
  author={Fan-Ming Luo and Tian Xu and Xingchen Cao and Yang Yu},
  booktitle={ Proceedings of the 12th International Conference on Learning Representations},
  year={2024}
}


@inproceedings{mobile@sun2023,
author = {Sun, Yihao and Zhang, Jiaji and Jia, Chengxing and Lin, Haoxin and Ye, Junyin and Yu, Yang},
title = {Model-Bellman inconsistency for model-based offline reinforcement learning},
year = {2023},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1378},
numpages = {18},
}



BibTeX
@inproceedings{dsconstraint@2023ran,
author = {Ran, Yuhang and Li, Yi-Chen and Zhang, Fuxiang and Zhang, Zongzhang and Yu, Yang},
title = {Policy regularization with dataset constraint for offline reinforcement learning},
year = {2023},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1192},
numpages = {17},
}


@inproceedings{rehearsing@2024jia,
author = {Chengxing Jia and Chenxiao Gao and Hao Yin and Fuxiang Zhang and Xiong-Hui Chen and Tian Xu and Lei Yuan and Zongzhang Zhang and Yang Yu and Zhi-Hua Zhou},
title = {Policy rehearsing: Training generalizable policies for reinforcement learning},
year = {2024},
booktitle = {Proceedings of the 12th International Conference on Learning Representations},
location = {Vienna, Austria },
series = {ICLR'24}
}

@software{Liu_LlamaIndex_2022,
author = {Liu, Jerry},
doi = {10.5281/zenodo.1234},
month = {11},
title = {{LlamaIndex}},
url = {https://github.com/jerryjliu/llama_index},
year = {2022}
}


@article{kamalloo2023evaluating,
  title={Evaluating embedding apis for information retrieval},
  author={Kamalloo, Ehsan and Zhang, Xinyu and Ogundepo, Odunayo and Thakur, Nandan and Alfonso-Hermelo, David and Rezagholizadeh, Mehdi and Lin, Jimmy},
  journal={arXiv preprint arXiv:2305.06300},
  year={2023}
}


@inproceedings{llmplanner@2023song,
  title={Llm-planner: Few-shot grounded planning for embodied agents with large language models},
  author={Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2998--3009},
  year={2023}
}

@article{drlc@2024cao,
  title={DRLC: Reinforcement Learning with Dense Rewards from LLM Critic},
  author={Cao, Meng and Shu, Lei and Yu, Lei and Zhu, Yun and Wichers, Nevan and Liu, Yinxiao and Meng, Lei},
  journal={arXiv preprint arXiv:2401.07382},
  year={2024}
}


@inproceedings{colbert@2022khattab,
  title={Colbert: Efficient and effective passage search via contextualized late interaction over bert},
  author={Khattab, Omar and Zaharia, Matei},
  booktitle={Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval},
  pages={39--48},
  year={2020}
}

@article{kwon2023reward,
  title={Reward design with language models},
  author={Kwon, Minae and Xie, Sang Michael and Bullard, Kalesha and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2303.00001},
  year={2023}
}


@article{liu2023llm+,
  title={Llm+ p: Empowering large language models with optimal planning proficiency},
  author={Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  journal={arXiv preprint arXiv:2304.11477},
  year={2023}
}


@article{zala2024envgen,
  title={EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents},
  author={Zala, Abhay and Cho, Jaemin and Lin, Han and Yoon, Jaehong and Bansal, Mohit},
  journal={arXiv preprint arXiv:2403.12014},
  year={2024}
}

@inproceedings{szot2023large,
  title={Large language models as generalizable policies for embodied tasks},
  author={Szot, Andrew and Schwarzer, Max and Agrawal, Harsh and Mazoure, Bogdan and Metcalf, Rin and Talbott, Walter and Mackraz, Natalie and Hjelm, R Devon and Toshev, Alexander T},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{ren2024bases,
  title={BASES: Large-scale Web Search User Simulation with Large Language Model based Agents},
  author={Ren, Ruiyang and Qiu, Peng and Qu, Yingqi and Liu, Jing and Zhao, Wayne Xin and Wu, Hua and Wen, Ji-Rong and Wang, Haifeng},
  journal={arXiv preprint arXiv:2402.17505},
  year={2024}
}

@article{mataten2008tsne,
  author  = {Laurens van der Maaten and Geoffrey Hinton},
  title   = {Visualizing Data using t-SNE},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {86},
  pages   = {2579--2605},
  url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}


@article{wu2024read,
  title={Read and reap the rewards: Learning to play atari with the help of instruction manuals},
  author={Wu, Yue and Fan, Yewen and Liang, Paul Pu and Azaria, Amos and Li, Yuanzhi and Mitchell, Tom M},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}



@inproceedings{hu2023instructrl,
author = {Hu, Hengyuan and Sadigh, Dorsa},
title = {Language instructed reinforcement learning for human-AI coordination},
year = {2023},
publisher = {JMLR.org},
abstract = {One of the fundamental quests of AI is to produce agents that coordinate well with humans. This problem is challenging, especially in domains that lack high quality human behavioral data, because multi-agent reinforcement learning (RL) often converges to different equilibria from the ones that humans prefer. We propose a novel framework, instructRL, that enables humans to specify what kind of strategies they expect from their AI partners through natural language instructions. We use pretrained large language models to generate a prior policy conditioned on the human instruction and use the prior to regularize the RL objective. This leads to the RL agent converging to equilibria that are aligned with human preferences. We show that instructRL converges to human-like policies that satisfy the given instructions in a proof-of-concept environment as well as the challenging Hanabi benchmark. Finally, we show that knowing the language instruction significantly boosts human-AI coordination performance through human evaluations in Hanabi.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {551},
numpages = {15},
location = {<conf-loc>, <city>Honolulu</city>, <state>Hawaii</state>, <country>USA</country>, </conf-loc>},
series = {ICML'23}
}


@article{xi2023rise,
  title={The rise and potential of large language model based agents: A survey},
  author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  journal={arXiv preprint arXiv:2309.07864},
  year={2023}
}

@misc{hu2024survey,
      title={A Survey on Large Language Model-Based Game Agents}, 
      author={Sihao Hu and Tiansheng Huang and Fatih Ilhan and Selim Tekin and Gaowen Liu and Ramana Kompella and Ling Liu},
      year={2024},
      eprint={2404.02039},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{guo2024large,
      title={Large Language Model based Multi-Agents: A Survey of Progress and Challenges}, 
      author={Taicheng Guo and Xiuying Chen and Yaqi Wang and Ruidi Chang and Shichao Pei and Nitesh V. Chawla and Olaf Wiest and Xiangliang Zhang},
      year={2024},
      eprint={2402.01680},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{levine2020offline,
      title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems}, 
      author={Sergey Levine and Aviral Kumar and George Tucker and Justin Fu},
      year={2020},
      eprint={2005.01643},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}